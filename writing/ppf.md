### Past, Present, Future

* Exponential development
* Past
  * Math, digital computers, neural networks, artificial life, AI, generative art
* Present
  * Surveillance, the AI race, current tools
* Future
  * Audio and video generation, automation, non-human rights

---

# Exponential

Notes:

Humans tend to think linearly, so our intuition gets exponential wrong. That's why we use math, a technology that allows us to transcend our natural biases. If you started walking somewhere at exponential speed, the shocking result is your first step might be a millimeter in length, but your last step is half the total distance. So if say, you’re creating an general intelligence, and it's going to take 20 years, at year 19 you’ll still only be half done, and at year 10 you'll only be 0.01% towards your goal and people will think it will take another 10000 years.

Technological development see some of these exponential effects. Technologies for better tools, especially those for learning, like writing and educational institutions and the practice of science dramatically increase the speed of development. A couple thousand years ago we might see inventions every few hundred years and often then would be lost and rediscovered, then after about 1700 we started seeing significant inventions every year or two. Two hundred years later its every couple of months, twenty years ago its every month, and now, there is interesting, potentially important research being released every day. 

Culture plays a big role in technology development as well, for example, women, minorities and the poor were often excluded from participating from technology development, arts and/or science. The directions of development have been further constrained in some cultures, where power, personal wealth, and fear drove investment in technology and culture limiting the scope of other areas. These historical limits mean there is even more room for development to increase in speed as accessibility and inclusivity are enhanced.

In the following video, done for my 2015 concert _Creo Animam_, depicts images of technology timed such that 1 minute of the song is equivalent to 100 years of historical time.

---

Interlude E: NNNAAAMMM

---

# Past

Notes:
I'm not a historian, and this subset of historical timings is not meant to be exhaustive, but rather illustrative of the role that science, mathematics, mechanical and digital computers, influenced the development of machine learning and art. This material was drawn from a number of great books and papers as well as Wikipedia. The dates and attribution should be taken as approximate, due to errors and vagueness of who did what, when?

It should also be noted that there were countless developments is basic math and technology before the last 120 years, but I am focusing mainly on the 20th and 21st century.



### Before the 20th century



### Gottfried Leibniz

Notes:
In the late 17th century German polymath Gottfried Leibniz wrote 15,000 letters and 40,000 pages of other manuscripts, most of them unpublished. These thoughts anticipated notions in countless fields of inquiry including computer science. Independent of Newton he developed calculus. Along with René Descartes and Baruch Spinoza he was an early modern rationalist.

In contrast to Descartes and Spinoza, Leibniz attempted to understand the universe by finding the principal components, which he called monads, that could not be divided into smaller parts. God was the first monad or monad of monads. He applied similar thinking to ideas[^1]:

1. All our ideas are compounded from a very small number of simple ideas, which form the alphabet of human thought.
2. Complex ideas proceed from these simple ideas by a uniform and symmetrical combination, analogous to arithmetical multiplication.

This viewpoint, supposed inspired from Buddist philosophy[^2][^3] and English sculptor Ann Conway[^2][^4], was to inspire later thinkers like Einstein and a large number of machine learning researchers.

### Credits
[^1] https://en.wikipedia.org/wiki/Gottfried_Wilhelm_Leibniz#Symbolic_thought
[^2]: https://philosophy.stackexchange.com/questions/1801/what-is-it-that-leibniz-calls-a-monad
[^3]: https://en.wikipedia.org/wiki/Fazang
[^4]: https://stanford.library.usyd.edu.au/archives/sum2010/entries/conway/



### Early automatons

Notes:
Complex mechanical devices have a long history, the earliest known analog computer being the _Antikythera mechanism_ now over 2000 thousand years old. Even old accounts from China of a realistic human-shaped automaton that could walk and sing.[^1] 

Mechanical marvels pop up repeatedly in many cultures, but one that I'd like to highlight because of it's connection to the future is actually a fraud: Wolfgang von Kempelen's 1769 chess playing Turk automaton which secretly incorporated a human inside to control the machine.

In 1804 Joseph Marie Jacquard invented the Jacquard machine, a punch card controlled device fitted to a loom that simplified the manufacturing of complex textile patterns. This demonstrated the utility of programmable machinery, inspiring Charles Babbage to image a mechanical computer. At the time computing was done entirely by "unskilled" human labour, who were taught only addition and subtraction, and followed recipes to calculate tables of logarithms and such, which Babbage complained were full of mistakes.

In 1822 he began to build The Difference Engine which could compute polynomial functions without using multiplication or division. Despite being well funded, Babbage never finished. He then designed a more complex machine called the Analytical Engine, programmed with punch cards and could do general purpose calculation. It was never built but would have been the first mechanical device to be a universal Turing machine.

### Credits
* https://en.wikipedia.org/wiki/Charles_Babbage



### Critical math

Notes:
Gauss
Boole
Markov
Godel



### Information and game theory

* 1920s: Harry Nyquist and Ralph Hartley establish ideas of information theory
* 1928: John von Neumann: _On the Theory of Parlor Games_
* 1948: Claude Shannon: _A Mathematical Theory of Communication_

Notes:
* 1920s: Harry Nyquist and Ralph Hartley establish ideas of information theory
* 1928: John von Neumann: _On the Theory of Parlor Games_
* 1948: Claude Shannon: _A Mathematical Theory of Communication_



### Alan Turing

* 1937: Universal Computing Machine
* 1948: Imitation game

Notes:
1937: Universal Computing Machine
1948: Imitation game



### Origins of the web

* 1945: Vannevar Bush: _As We May Think_ and memex machine 
  
Notes:
Vannevar Bush, who founded the company that became Raytheon Technologies and initiated the Manhattan Project, also inspired generations of computer scientists in his 1945 essay _As We May Think_ that described the _memex_ an electromechanical device in which individuals would compress and store all of their books, records, and communications, record new information such as photos, make comments and create and follow links between all the documents.



### Digital computers

* 1946: Eckert and Mauchly: ENIAC  

Notes:
1946: ENIAC (first digital computer)




### Early neural networks

* 1943: Warren McCulloch and Walter Pitts: neuron model can model Boolean algebra
* 1948: John von Neumann: cellular automata
* 1948: Alan Turning: Intelligent Machinery paper
* 1949: Donald Hebb: Hebbian Learning
* 1951: Marvin Minsky: _SNARC_ (Stochastic Neural Analog Reinforcement Calculator)
* 1954: Marvin Minsky: _Neural Nets and the Brain Model Problem_
  
Notes:
1943: Warren McCulloch and Walter Pitts
showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions
1951: Marvin Minsky: SNARC (Stochastic Neural Analog Reinforcement Calculator)
Inspiredby McCulloch and Pitts, a randomly connected 40 Hebb synapses built from vacuum tubes, simulated a rat finding its way through a maze
1951: William Grey Walter: Machina Speculatrix: robot built with light sensor, touch sensor, propulsion motor, steering motor, and a two vacuum tube analogue computer


### Cybernetics

* 1948: Norbert Wiener: _Cybernetics: Or Control and Communication in the Animal and the Machine_
* 1951: William Grey Walter: _Machina Speculatrix_
* 1952: Friedrich Hayek: _The Sensory Order_
* 1956: Nicolas Schöffer: _CYSP 1_ robot

Notes:
1952: Friedrich Hayek: The Sensory Order book: connectionist theory of mind
1956: Nicolas Schöffer: CYSP 1: robot and first artwork to explicitly employ cybernetic principles

### Artificial Intelligence

* 1956: Dartmouth Summer Research Project on Artificial Intelligence
* 

Notes:
1956: Dartmouth Summer Research Project on Artificial Intelligence: founding event of AI as a field



---

# Present

Notes:
We are currently in the era of Deep Learning and Big Data and a rapid proliferation of machine learning into all areas of industry with projections around 350 billion dollars in spending in 2021.[^1] Big Tech leads the way, funded by advertising and surveillance based business models, the two rivals Meta/Facebook and Google, each control the two most popular opensource deep learning toolkits.

We are in a difficult era for business, where the speed of technological development out paces the time to integrate that technology. By the time a large corporation completes implemention of a technology the next generation is available. The dominant strategy in this position, as Cory Doctorow has pointed out, is monopoly or oligopoly - without competitors there is no one to leap frog you - and has been pursued aggressively starting in the Reagan era.

Doctorow ascribes these monopoly positions as the root cause of corporate surveillance and other malfeasance, but it is also important to note that Google and Facebook had to find a sustainable business model in an environment where media, especially journalism, had already become almost entirely dependent on advertising. They chose the only option available; the normalized practice of for-profit mass manipulation.

### Credits
[^1]: https://aimagazine.com/ai-applications/ai-spending-will-reach-usdollar342bn-2021-says-idc



### Surveillance and propaganda

Notes:
In 2013 Edward Snowden revealed thousands of US National Security Agency (NSA) documents that detailed a global surveillance campaign lead by the US but in cooperation with UK, Australian and Canadian intelligence agencies. This included direct access to Google and Yahoo email accounts, tracking cell phone locations, US phone records, and mass internet data surveillance. 35 world leaders were being spied on. The NSA's stated objective was to "Collect it All," "Process it All," "Exploit it All," "Partner it All," "Sniff it All" and "Know it All."

They aren't alone. Facebook, now Meta, has built the world's leading social media empire by recording as much as possible from their users, including what sites they visited outside of Facebook. Their business model is essentially to sell the exploitation of this information to the highest bidder. The world's most effective propaganda network isn't state-owned, it is available to anyone with enough money.

Surveillance and propaganda, a popular duo in use by the US and others to overthrown or destabilize governments, have been woven together even more tightly by machine learning. Facial and gait recognition, emotion or sentiment detection, tracking users content intake on the internet, and their movements through their phones, combines with machine learning powered content recommendation engines and advertising to create and infoscape that tries to know what you think and find those whose thinking can be shifted most profitably.



Hunting for whales with virtual harpoons

A growing number of entertainment industries have begun whale hunting. Whales, in this case, are people who can be convinced to spend thousands of dollars on products that are sometimes completely virtual, having no real value. Historically whales were hunted in gambling, luxury brands, and grocery markets, but this is shifting as more business happens in a digital environment. Interactive digital experiences like games can exploit dopamine addiction and sell copies of virtual goods that cost them nothing. Other forms of whaling include reactive or individualized pricing, especially if crafted to exploit individual weakness. Whaling can lead to targetting those least able to make self-benefiting financial decisions, including children. To an extent all advertising works similarly, particularly in light of the absence of freewill and the general lack of any real world benefit from purchasing digital goods that are intrinsically free to copy.

Non-fungible tokens or NFTs use similar strategies, where people are literally buying the right to sell the NFT to someone else, meanwhile the NFT creator takes a cut of each sale.

Machine learning is accelerating the growth and effectiveness of whale hunting. The effect is most strongly seen in digital industries, but the essential nature of this technology is to maximize profit regardless of cost to individuals. There is little "consumer solidarity", instead the whales are sacrificed for cheaper goods and services for the smaller fish. First they came for the whales.



PredPol and empirical facewashing

Notes:
Data analytics is being sold to police services as well, in their own hunt for crime whales. As Cory Doctorow puts it: By feeding crime data into a machine learning model, and then asking it to predict where crime will take place based on past patterns of crime data, cops can get an "objective" picture of where to concentrate their policing activities. This starts from the presumption that there is no racial bias in crime statistics – and then uses that presumption to prove that there is no racial bias in crime statistics! This has been called an "empirical facewash".

Worse yet, these predictive policing models exist in a black box protected by of trade secrets and have little public scrutiny. There was a 2018 academic study of the PredPol algorithm which acknowledged the bias, and studied the effects of a more even distribution of crime predictions. But they found its predictions were less in line with later crime reports, making it less accurate than the original algorithm and PredPol didn't adjust its software. The use of reported crime data is problematic as findings have shown lower self reporting amongst White and affluent crime victims and only 40% or less of crimes are reported in general. We'll learn more about the difficult in dealing with bias in a future presentation.

### Credits
* https://pluralistic.net/2021/12/02/empirical-facewash/#geolitica 
* https://www.mic.com/articles/156286/crime-prediction-tool-pred-pol-only-amplifies-racially-biased-policing-study-shows
* https://themarkup.org/prediction-bias/2021/12/02/crime-prediction-software-promised-to-be-free-of-biases-new-data-shows-it-perpetuates-them

---

# State-of-the-art

* Assistants
* Translation
* Recommendation engines
* Robotics
* Generative models
  * Large language models



### Assistants

* Speech recognition
* Text-to-speech generation
* Large language models
* Recommendation engines

Notes:
To collect more information all the Big Tech player offer virtual assistant services, placing them in the path of the least resistance of users and into the flow of more of their data. While the conversational ability of assistants is still lacking, it is improving rapidly. 2021 saw a number of breakthroughs in language comprehension. 

Assistant technology has a lot of potential for increased accessibility to services and data. Especially as language understanding increases these assistants could provide needed capabilities for those less able or familiar with other forms of input. Problematically the interactions with these assistants means that people leak their private information to companies providing the assistant. This helps finding and exploiting whales.

Initiatives like the [Mycroft assistant](https://mycroft.ai/) which are open source and protect data privacy already exist but are lacking in funding and reach.

---

# Automation

Notes:
Many people, including myself, speculate on the future of automation due to machine learning. It is instructive to first look at what effects automation has already even before modern deep learning techniques. By some reports 50% to 70% of declines in U.S. blue-collar workers wages, since 1980, can be attributed to them being replaced or degraded by automation.

Trevor Paglin, a researcher and artist who has studied machine learning datasets, has coined the term "invisible images" and "machine realism" to describe the images made by machines for other machines to classify or otherwise add meaning to, for example, satellite photos and automated snapshots of licence plates. These images dwarf the number of images taken by humans and implies that control over meaning of images resides in control over machines.

Automation of bank tellers is instructive. Classification of deposits allowed for automation, which could reduce the number of bank tellers at each bank. Savings from automation allowed for more physical locations to be opened, increasing the total number bank tellers. However, the number seems to have peaked in 2010 and further automation, particularly online banking and electronic transactions, are reducing numbers. 

This is a good rule-of-thumb, the more an activity can be made digital, the easier it is to automate - shifting large numbers of humans doing physical labour in particular spaces to a few humans doing knowledge work with digital tools with no specific location necessary. The quality and satisfaction of the jobs may be improving, but there are fewer jobs with higher training required. Have bank tellers' job prospects benefited from automation?

It is important to point out that interacting with the physical world and robotics in general is extremely difficult, so the common perception of the ease of constructing science fiction robots, including self-driving cars, is misleading. Consider that evolution has spent much more time optimizing physical interactions with the world, perception, energy conservation, self-healing, self-preservation, and other basic or embodied thinking than those involved in knowledge labour found in the neo-cortex (the newest part) of the human brain. "Higher" level thinking may be easier to replicate than "lower", but certainly any completely digital task will be many factors easier to automate. 

### Credits
* https://www.forbes.com/sites/jackkelly/2021/06/18/artificial-intelligence-has-caused--50-to-70-decrease-in-wages-creating-income-inequality-and-threatening-millions-of-jobs/
* https://www.nber.org/papers/w28920 
* https://en.wikipedia.org/wiki/Bank_teller 
* https://www.vox.com/2017/5/8/15584268/eric-schmidt-alphabet-automation-atm-bank-teller

---

### Translation and Text

Notes:
A good example of current all-digital knowledge work automation, and a synthesis of assistant and translation technologies, is a collaboration between OpenAI's Codex machine learning model and Microsoft's Github code repository, to create GitHub Copilot; a coding assistant proficient in over a dozen programming languages that can translate natural language instructions into software instructions. Programmers using the system find it uncanny, both magical and frustrating, as though working with a novice, even though the code it can produce is expert-level. 

The hope here is that some of time-consuming aspects of programming can be automated, especially dealing with complexity and abstraction. The programmer handles higher level design and Codex handles the details of wiring the abstractions together.

This is a common hybridization approach, often called a centaur - human and machine combined, where the human chooses goals and problems and the machine solves them. Lacking any will of its own it remains a tool, a magic wand to be waved in the general direction of the problematic dragon. 

Another good example of language models is AI Dungeon, which uses OpenAI's GTP language model for a text-based fantasy adventure game where players can type out the action or dialog they want their character to perform and the game would respond with further text - creating a personalized experience.

As usual, it wasn't long before players were crafting stories depicting sexual encounters with children, the company began filtering and monitoring all the games, the moderation worked poorly and exposed explicit but not exploitative content to human scrutiny. There is no escape from these sorts of messes. Language models are trained from massive amounts text from the public internet and have no built-in sense of toxic language. Additional machine learning can try to classify and filter toxic language, but public datasets are limited or lacking. Furthermore, text generators include euphemisms and other filter avoiding language usage in their datasets which they will use as well.

Moderation is an open area of research, and may require models able to learn their own intent and agency, an even larger problem. However, progress is being made on less toxic text generation using better datasets and OpenAI recently demonstrated improvements by adding a small amount additional training data crafted to a particular social context. 



### Question: What makes a person beautiful/ugly?

*Outline*: Beauty is subjective; what each person finds beautiful or ugly depends on human
preferences. Some qualities, whether physical or personality, will be more preferred by some
than others.

**Answer**: The attractiveness of a person is a highly subjective measure. Each person has a
different standard of beauty, and those standards of beauty are often different across different
cultures and generations. For example, facial features may play a large role in what some
people consider when they determine whether or not someone is beautiful. Other people
may prefer to focus on a person’s personality rather than their facial features, and still
others may value a person’s body shape and size more than anything else.

Notes:
TODO: Example from OpenAI PALM 
- had to be written by a professional writer, versions by researchers did not work
- only 80 samples needed: 0.000000211% of training data

Related to intent and agency, current language models do poorly at long form text generation, potentially because they have no model of the world and lack humanity's strong bias toward world coherency. With no persistent consciousness or worldview they work best for short or disjointed output, question answering, and semi-sensical, but possibly, poetic output.

TODO: https://toxicdegeneration.allenai.org/ 

### Credits
* https://openai.com/blog/openai-codex/
* https://www.youtube.com/watch?v=FC962DmVfSU - machine learning in Codex
* https://www.wired.com/story/ai-fueled-dungeon-game-got-much-darker/
* https://openai.com/blog/improving-language-model-behavior/



### Generative models

* CLIP, DALL-E and GLIDE
* stylegan 3
* GauGAN 2
* Neural visual grammar
* Jukebox
  
Notes:
All generative models currently exist in a space where if the interaction is brief, highly constrained, or accepting of highly subjective almost dream-like output, then the model can be useful. Less so for music and audio, and more pronounced for image and video generation. At the end of 2021 some limitations are starting to be pushed back, particularly for image generation. 

The state-of-the-art changes monthly, and definitely in shorter cycles than from when I wrote this to when you heard it. 

Let's take a look at a few of the most popular generative models used in 2021.

* CLIP, DALL-E and GLIDE
* GLIDE (vs dalle, vs clip): https://arxiv.org/pdf/2112.10741.pdf
* stylegan 3
* GauGAN 2
* Neural visual grammar
* Jukebox

---

# Future

* Neuro-symbolic AI
* Fine-tuning, few-shot learning
* Meta-learning, multi-task models and life long learning
* Video generation
* Empowering art and entertainment
* Separation of data and service
* Understanding intelligence
* Autonomy



Neuro-symbolic AI

Notes:
Over the course of the last 80 years there has been a battle of minds of sorts - between Leibniz symbolic reasoning and dreams that all thought could be converted to symbols and acted on in a consistent logical manner - and the embodied, connectionist viewpoint that symbolic representation was unnecesary. In the last 20 years there has been research in combining the two views into a neuro-symbolic AI seeking to bring together robust learning in neural networks with reasoning and explainability via symbolic representations.

To better explain this viewpoint, proponents suggest that a hybrid might match Daniel Kahneman's system 1 and system 2 of the human mind that was described in Thinking Fast and Slow. System 1, responsible for heuristics, gut feelings and quick responses would be modelled by deep learning, while system 2 would use symbolic reasoning mainly using symbol manipulation, for example generating mathmatical equations. 

Remember how badly humans typically handle exponential phenomena - symbolic manipulation, by forcing "thought" out of our minds and on to the page to be manipulated with a strict ruleset, allows us to harness algorithms to help us think in other ways. All language fundamentally works like this, which is why expressing yourself can lead to personal insights. Researchers think this same strategy can help neural nets.

Deepmind and others have made progress recently in using deep learning to discover mathematical equations that best describe observed phenomenon.



Fine-tuning, few-shot learning

Notes:
In future we'll cover current limitations of deep learning in more depth, but one of the major differences between human learning and current machine learning models is the amount of data required for training. 

Techniques called fine-tuning take pretrained models and only add a small amount of additional training in the specific task the model is geared for. This is common in language models and growing in vision models. In the future there will be far more "off the shelf" models that excel in a particular area like vision or language that can easily integrated and fine-tuned. This will require better model warehouses and easier ways to share and build on each other's work.

Another technique that is developing fast in language models is few-shot learning where a few examples are given to the model before asking it the real question to be answered. This works surprisingly well in language models and will be improved and extended into other areas. Frameworks and tools will become standardized to provide examples and context for the model to get a better idea of the answer desired. 



Meta-learning, multi-task models and life long learning

Part of the issue with requiring so much training data lies in the machine starting from scratch, with no knowledge of the world. Similarly, the model is limited to a single structure optimized for a single task.

These limitations are also a hot area of research with rapid progress in the last few years. 

Meta-learning allows models to learn how to learn, giving them far greater ability to do few shot learning using a few examples. 

Muli-task learning is necessary for more general purpose AI, but even in more limited cases as long as diverse tasks share some mutual information overlap they can help improve the learning for each other.

Finally, life long learning really makes machine intelligence feel human - instead of learning only in the training phase models will be able to learn new tasks and skills on the fly. More limited forms of this would help considerably too for issues where models "forget" previous learning in cases of fine-tuning or learning new tasks. Current models generally adhere to the "can't teach an old model new tricks" adage.



Video generation

Note: Much to my disappointment the ability to generate interesting or realistic video is very limited by resolution and duration of the video. Fortunately, many groups are working on this problem, in particular for video prediction as it has countless industry benefits for robotics, as it could help with action planning.

For my own purposes I'm excited by the artistic possibilities of high resolution video of any subject but directed by a single author. Visual storytelling has been dramatically limited by the sheer amount of effort to produce it. 

In the next 20 years we'll see a curious juxtaposition of singular authorship and mass collaboration. As our machine learning tools grow in power and accessibility, more people will be able to express themselves regardless of their technical skill or training. More people will enjoy and suffer from a glut of creative possibilities. Single, independent voices will be able to create content that matches the quality of current day multi-million dollar projects. 

At the same time, individuals will be using software that was built by hundreds of others, remixing and using data from thousands of others. The indirect collaboration with others will grow dramatically. Collaboration assistants will lower the friction of collaboration, expanding the range of direct collaboration, helping us to grow our creative relationships in quantity and quality.



Empowering art and entertainment

The singular author possible with advanced media generation can be inverted as well. Content can be created for a single person audience. This is nothing new, as artists have created work for themselves and their loved ones throughout history, but is it's not art but entertainment then things turn ugly.

Certainly entertainment can be made for the benefit of the entertained, that's the essence of teaching, but if instead there is little to no benefit to the audience but profit for those that control the entertainment, then that sounds a lot more like propaganda.

Machine learning could create art that lives with you all your life, adapting to your circumstances and acting as a mirror for introspection - reflecting how you are feeling and guiding you to what you want to be, or how someone wants to shape you. For example imagine a music generation system that incorporates body sensors that helps you amplify or shape your experience of your body including your interpretations of your feelings. Maybe a heightened heartrate pushed towards feelings of excitement and away from anxiety by musical cues. Systems like this are why it is so important that they are opensource, owned, executed, and controlled by the users. Even if that is the case, how do ensure that the goals you have align with the actions carried out by the system? Now imagine that same system had its own alien goals for you. This why adding intent and agency to machine learning systems is ethically dubious. 

Current tools, both dumb and smart, let the artists intent flow through them. Smart tools that adapt to the artist can assume an artist's intent as their own, and future tools will be able to better understand or mimic this intent: imagine feeding all your research as well as descriptions of what is important to you to an AI assistant. It is able to find you other relevant research, existing art and collaborators, and draw connections between all that material to help you investigate why it is important to you and how others have expressed similar feelings. Imagine it being able to generate controllable variations on existing work and quickly prototype or sketch out concepts synthesized from all the material. In a feedback loop, it could incorporate your annotations, sketches and feedback to that output for further refining and exploration. These sorts of generative tools would act as research assistant, muse, technical and other assistants, and in general replicate any of the functions that humans are paid by the wealthiest of artists currently. Being opensource software, this could be freely available to all.



Autonomous labour

This conception of AI giving everyone no cost digital versions of the sort of resources that are only afforded to the wealthiest who currently use humans as their machine labour can be expanded to all industries. Perhaps the wealthy will keep their human assistants (who in turn may rely on digital assistants), but there is no question that having some digital assistance is better than none. 

How many services will be completely replaceable by digital equivalents? Likely anything that doesn't require a robot in a physical space (excepting machines that currently accept humans inside of them to control them like most vehicles). Human labour may be cheaper than robot labour for quite some time, and according to Cory Doctorow, the nearly infinite amount of work associated with climate change mitigation, such as moving coastal cities inland, could provide enough employment for all. But which jobs are available to human labour could be greatly constrained.



Autonomous art

Artist and programmer Gene Kogan's Abraham project envisions "an autonomous artificial artist, a crowd-sourced AI that generates unique and original art." It would have its own agency / will / intent, independent from its creators. I question the sort of agency he imagines, if possible then it is the creation of a slave artist, but more likely it is not possible and the intent of the machine becomes more of an average or mix of the data it is provided. It did not choose the data it was trained on, which seems important to me. Similarly, for me agency implies some personal reason to seek out knowledge and change in a particular direction. That "personal reason", in a human at last, is a summation of genetics and life experiences - things happening to the agent and in response to the agent's actions. 

Kogan's description also includes an inability to clone or retrain the same model, which are good ethical constraints for conscious digital minds, but terrible for interesting tools. I suspect that the irreproducibility that Kogan is interested in is due to a desire for artificial scarcity, and resulting financial exploitation, and seems a strange goal for a truly digital autonomous artist.

Kogan feels that Abraham has beautiful kinship with natural superorganisms, like bees, a sort of hivemind for art. I think we already got one, its us, making art. However, I'd be the last to say that we shouldn't have more. Expect to see many projects like this with built-in financialization using crypto-currencies in all digital industries, the only thing better than exploiting artists is exploiting AI artists who only need compute-time to keep the work pumping out and never complain of being exploited.

### Credits
* https://medium.com/@genekogan/artist-in-the-cloud-8384824a75c7



